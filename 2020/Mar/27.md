# March 27th 2020

Today I was mostly working with stolon. We were trying to do an automatic,
immediate and smooth failover of a master keeper when it goes down

For this we decided to write a golang program which will run in every stolon
keeper as a prestop command

Let me give some context on what we are trying to do, the goal and why.

So, we use GKE clusters. We are using some old versions of Kubernetes master and
Kubernetes node (kubelet version). We are getting force upgraded sometimes and
when nodes are upgraded - our stolon keepers running in the cluster face big
downtime. We wanted to do the version upgrade ourselves and also in a controlled
manner, with minimal downtime. The nodes get upgraded at a node pool level. So,
GCP has this concept of node pools - where one node pool is a group of nodes and
for regional GKE clusters, each node pools has nodes from across different zones
and any operation is usually done at node pool level, two of which I'm familiar
with are - scaling up nodes, version upgrades

Our idea to reduce downtime for stolon cluster was this - when a node is going
to be upgraded, it's cordoned and drained. While draining, the pods in it die.
Now, when a pod which is a master stolon keeper goes away, it takes some time
for the sentinel to re elect another master after realising the master keeper
is dead for some time (some timout interval) after its check (there's check
interval time too) and also, our Postgres cluster has asynchronous replication,
and it has one master keeper and two async replicas. We didn't want data loss
during our node upgrade. So, this is what we decided, we will control the
downtime and try to make it as smooth and fast as possible in an automated
manner.

Kubernetes containers lifecycle prestop command and graceful period - 
https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks

During the pre stop, we plan to first check if the current keeper, where the
command is running, is master or not. 

If it's not a master, meaning a follower / secondary keeper, we silently exit

If it's a master, we wanted it to elect a new master when it goes down. I'll
tell how we are planning to do this, but one question would arise now - why only
run it when it's a master?

Now, let's say we run it in followers too - well, now many are doing master
switch over, multiple times when they go down, but for what? And if you run it
ONLY in the followers, why would you do that? There are still multiple followers
in our case, which is 2 for some of the stolon clusters, so, multiple switch
overs will happen when each follower goes down one by one. Instead, it's better
if just the master can do re election of another master when it goes down, with
0 data loss and minimal downtime. And it's okay if a secondary becomes master
and then becomes the next node to be upgraded. It will all still be smooth. The
best case is, when the nodes with the secondary keepers upgrade first and then
the master, in which case, just one master switch. But hey, we have lots and
lots of stolon keepers, across all our nodes. So, given a node, multiple may be
secondary keepers, multiple may be masters. We cannot control that, also, we
have put anti affinity to make sure each keepr pod of a stolon cluster is a
different node in a different zone.

So, how are we planning to do this? Now, when the master keeper pod is going to
be killed, the pre stop command will run, which will do multiple things - since
the keeper is master, it continues it's work by 
1. first making the replication synchronous. This is to avoid data loss. This
creates the kind of replication where the wal logs of Postgres are sent to the
synchronous standbys first and then a response to the client is sent. but it
doesn't mean the wal logs are replayed / applied in the standby. We were okay
with this - as we knew the standby still has the wal log to replay or apply
before it becomes a master. So the standby's still an eligible candidate to
become a master
2. Next check if the replication is synchronous. For this we used the psql query
3. Next intentionally fail the master keeper
4. Wait for new master keeper to come up
5. Make the replication asynchronous
6. Exit

Now we did this manually and succeeded. We also automated it. We did notice some
issues and edge cases during these steps. We are yet to find a solution to all
of em but some of issues are this - 
1. What will happen if the sync standby goes down for some reason? We will have
only one async standby remaining and it takes quite some time for stolon to make
the async standby sync due to some slow timeouts (fail interval) and also, when
a sync standby goes down, the writes to the database are blocked! Only reads are
allowed! We decided to reduce the fail interval time to very low - 5 seconds
2. What will happen if the master keeper pod that's going to be killed becomes
the master again due to some reason? We noticed that this happened a lot of
times when our automation immediately failed the keeper when the replication
was in sync - state was `streaming` and sync state was `sync`. We realized
that we need to wait for sometime after it becomes synchronization. We still
need to understand about why that's the case
3. We made sure that our automation finishes off as soon as possible - within
around 30 seconds as this is the default grace period for a pod to run it's
pre stop command before it gets killed. So, whatever happens we need to run
within this time. Or else, we need to at least increase this grace period.
And also try to understand point 2 to see how much we need to wait for
replication to be in sync mode. 

Other than this, there were some good adventures with stolon. Some of the
commands that I ran a lot today are

```
$ # making replication sync
$ stolonctl update --patch '{ "synchronousReplication": true }'
$ # making replication async
$ stolonctl update --patch '{ "synchronousReplication": null }'
$ # setting fail interval
$ stolonctl update --patch '{ "failInterval": "5s" }'
$ # reading cluster data. this was in old version of stolonctl
$ stolonctl clusterdata
$ # at times I used the latest version of stolonctl >= 0.14.0
$ # latest versions have clusterdata read and write too
$ # as separate sub commands
$ stolonctl clusterdata read
$ # only in the latest versions failkeeper command is present
$ # starting from v0.13.0
$ stolonctl failkeeper keeper0
$ stolonctl status
$ watch "stolonctl status"
$ watch "stolonctl status | tail"
```

I was also using `jq` to help with reading data from the clusterdata

```
$ # to find the status of the stolon cluster
$ stolonctl clusterdata | jq ".cluster.status"
$ # to find the master db uid of the stolon cluster
$ stolonctl clusterdata | jq ".cluster.status.master"
$ # to find the health status of the master
$ master=$(stolonctl clusterdata | jq ".cluster.status.master"); stolonctl clusterdata | jq ".dbs.${master}.status.healthy"
$ # to find the master db uid and the health status of the master in watch mode
$ watch 'master=$(stolonctl clusterdata | jq ".cluster.status.master"); echo $master; stolonctl clusterdata | jq ".dbs.${master}.status.healthy"'
```

And in the master keeper, I used psql and got replication status

```
$ PGPASSWORD=$(cat $STKEEPER_PG_SU_PASSWORDFILE) psql -h localhost -U $STKEEPER_PG_SU_USERNAME -d postgres

psql> select * from pg_stat_replication;

psql> select client_addr, sync_state, state, sent_location, replay_location, sync_priority from pg_stat_replication;

psql> select client_addr, sync_state, state, sent_location, replay_location, sync_priority from pg_stat_replication where sync_state='async' and state='streaming';

psql> -- to run the above command in watch mode every 2 seconds
psql> \watch

psql> -- to run the above command in watch mode every 1 second
psql> \watch 1
```

That's all I did today. I guess I covered quite some stuff ðŸ¤”

---------

Oh yes, one more thing I did was - use timers and tickers for the automation
for checking if replication is in sync or to check if new master has come up.
We used ticker for doing checks in intervals and used timer for timeout!

https://gobyexample.com/tickers
https://gobyexample.com/timers

there was confusion about break statement in our code - what will it break, when
in a select statement, and the select statement is inside a for loop. Does is
break the select or the for loop?

http://stackoverflow.com/questions/11104085/ddg#11105482

It's the innermost block - which is select in our case :)

--------

while talking about Databases, we were discussing about Amazon DynamoDB - how
it has quite some performance based on our colleagues comments, and then
spoke about Azure CosmosDB, and then GCP Cloud Spanner and then it's research
paper -

https://duckduckgo.com/?t=ffab&q=spanner+research+paper&ia=web

https://research.google/pubs/pub39966/

--------

And then I was checking a bit about VNC - Virtual network computing

https://duckduckgo.com/?t=ffab&q=virtual+network+computing&ia=web

https://en.wikipedia.org/wiki/Virtual_Network_Computing

------

I learned to use comments in SQL -

https://www.w3schools.com/Sql/sql_comments.asp

------

Don't Just Learn To Code, Learn To Create | Justin Richards | TEDxYouth@ColumbiaSC
https://www.youtube.com/watch?v=6rxWc-TNIJI
